# Ray on Kubernetes - Best of both worlds
# Using KubeRay Operator

# 1. Install KubeRay operator first:
# helm install kuberay-operator kuberay/kuberay-operator

# 2. Define a RayCluster custom resource
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: ml-ray-cluster
spec:
  # Ray head node
  headGroupSpec:
    rayStartParams:
      dashboard-host: '0.0.0.0'
    template:
      spec:
        containers:
        - name: ray-head
          image: rayproject/ray-ml:2.9.0-gpu
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
            requests:
              cpu: "2"
              memory: "8Gi"
          ports:
          - containerPort: 6379  # Redis
          - containerPort: 8265  # Dashboard
          - containerPort: 10001 # Client
  
  # Ray worker nodes
  workerGroupSpecs:
  - replicas: 4
    minReplicas: 1
    maxReplicas: 10  # Auto-scaling!
    groupName: gpu-workers
    rayStartParams: {}
    template:
      spec:
        containers:
        - name: ray-worker
          image: rayproject/ray-ml:2.9.0-gpu
          resources:
            limits:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"

---
# 3. Service to access Ray cluster
apiVersion: v1
kind: Service
metadata:
  name: ray-cluster-head-svc
spec:
  selector:
    ray.io/cluster: ml-ray-cluster
    ray.io/node-type: head
  ports:
  - name: dashboard
    port: 8265
    targetPort: 8265
  - name: client
    port: 10001
    targetPort: 10001

---
# 4. Your Python script (much simpler!)
# train_on_ray.py - submit this to Ray cluster running on K8s
"""
import ray
from ray import train
from ray.train.torch import TorchTrainer
from ray.train import ScalingConfig

# Connect to Ray cluster running on K8s
ray.init(address="ray://ray-cluster-head-svc:10001")

# Same simple Ray code from before!
def train_func(config):
    import torch.nn as nn
    import torch
    from ray import train
    
    model = nn.Linear(128, 10)
    model = train.torch.prepare_model(model)  # Ray handles DDP
    
    for epoch in range(10):
        # Training code - Ray handles distribution
        loss = torch.randn(1)
        train.report({"loss": loss.item()})

# Ray automatically uses the K8s GPU workers
trainer = TorchTrainer(
    train_func,
    scaling_config=ScalingConfig(
        num_workers=4,  # Uses 4 K8s pods with GPUs
        use_gpu=True,
        resources_per_worker={"CPU": 4, "GPU": 1}
    )
)

result = trainer.fit()
print(result.metrics)
"""

---
# 5. RayJob - Submit jobs declaratively via K8s
apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: training-job
spec:
  entrypoint: python train_script.py
  runtimeEnvYAML: |
    pip:
      - torch==2.0.0
      - transformers==4.30.0
  
  # Reference existing cluster
  clusterSelector:
    ray.io/cluster: ml-ray-cluster
  
  # Or create a new cluster for this job
  rayClusterSpec:
    headGroupSpec:
      template:
        spec:
          containers:
          - name: ray-head
            image: rayproject/ray-ml:2.9.0-gpu
    workerGroupSpecs:
    - replicas: 4
      groupName: workers
      template:
        spec:
          containers:
          - name: ray-worker
            image: rayproject/ray-ml:2.9.0-gpu
            resources:
              limits:
                nvidia.com/gpu: 1

---
# 6. Access Ray Dashboard via port-forward
# kubectl port-forward service/ray-cluster-head-svc 8265:8265
# Then visit http://localhost:8265

# Submit job from local machine:
# ray job submit --address http://localhost:8265 -- python train_script.py